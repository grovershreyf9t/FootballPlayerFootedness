{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:12:01.080988Z",
     "start_time": "2020-10-22T15:12:01.065029Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import umap.umap_ as umap\n",
    "import hdbscan\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option(\"display.max_rows\", 3000)\n",
    "pd.set_option('use_inf_as_na', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:12:03.655119Z",
     "start_time": "2020-10-22T15:12:02.306713Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/defender_clusters/defender_vectors.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6187a1ee341d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdef_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/defender_clusters/defender_vectors.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# 1) try standard library Pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/defender_clusters/defender_vectors.pkl'"
     ]
    }
   ],
   "source": [
    "def_vectors = pd.read_pickle(\"../data/defender_clusters/defender_vectors.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:12:06.517924Z",
     "start_time": "2020-10-22T15:12:05.927503Z"
    }
   },
   "outputs": [],
   "source": [
    "def_vectors[def_vectors['player_name'].str.contains(\"Vert\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:12:07.188754Z",
     "start_time": "2020-10-22T15:12:07.173745Z"
    }
   },
   "outputs": [],
   "source": [
    "def_vectors = def_vectors[def_vectors['progaccpass'] + def_vectors['proginaccpass'] > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:12:07.790643Z",
     "start_time": "2020-10-22T15:12:07.778672Z"
    }
   },
   "outputs": [],
   "source": [
    "def_vectors.reset_index(inplace=True)\n",
    "def_vectors.drop(['index'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:12:08.480647Z",
     "start_time": "2020-10-22T15:12:08.458658Z"
    }
   },
   "outputs": [],
   "source": [
    "def_vectors['progaccpass_pm']=def_vectors['progaccpass']/def_vectors['matches_played']\n",
    "def_vectors['proginaccpass_pm']=def_vectors['proginaccpass']/def_vectors['matches_played']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:12:08.885559Z",
     "start_time": "2020-10-22T15:12:08.874587Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['player_name','team','position','footedness','progaccpass_pm','proginaccpass_pm','progpreference_per_region','progaccuracy_per_region','total_off_region_per_pass','off_avgcontri','off_val_opp_avg']\n",
    "def_vectors_fil = def_vectors[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:12:09.176298Z",
     "start_time": "2020-10-22T15:12:09.158398Z"
    }
   },
   "outputs": [],
   "source": [
    "def_vectors_foot_sep = pd.get_dummies(def_vectors_fil,prefix=['foot'],columns=['footedness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:12:09.453707Z",
     "start_time": "2020-10-22T15:12:09.438749Z"
    }
   },
   "outputs": [],
   "source": [
    "def_vectors_foot_sep['position'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:12:09.792850Z",
     "start_time": "2020-10-22T15:12:09.773904Z"
    }
   },
   "outputs": [],
   "source": [
    "def ind_cols(df):\n",
    "    df1 = pd.DataFrame([sub_list[4:] for sub_list in df['progpreference_per_region'].tolist()], columns = ['att_LF_pref','att_LC_pref','att_RC_pref','att_RF_pref'])\n",
    "    df2 = pd.DataFrame([sub_list[4:] for sub_list in df['total_off_region_per_pass'].tolist()], columns = ['att_LF_off','att_LC_off','att_RC_off','att_RF_off'])\n",
    "    df3 = pd.DataFrame([sub_list[4:] for sub_list in df['progaccuracy_per_region'].tolist()], columns = ['att_LF_acc','att_LC_acc','att_RC_acc','att_RF_acc'])\n",
    "    df4 = pd.DataFrame(df['off_avgcontri'].tolist(), columns = ['att_LF_offcontri','att_LC_offcontri','att_RC_offcontri','att_RF_offcontri'])\n",
    "    df= pd.concat([df,df1,df3,df2,df4], axis = 1)\n",
    "    df.drop(['progpreference_per_region','progaccuracy_per_region','total_off_region_per_pass','off_avgcontri'], axis = 1, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:12:10.130797Z",
     "start_time": "2020-10-22T15:12:10.104868Z"
    }
   },
   "outputs": [],
   "source": [
    "def_vectors_ind_footsep = ind_cols(def_vectors_foot_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:12:10.664441Z",
     "start_time": "2020-10-22T15:12:10.618535Z"
    }
   },
   "outputs": [],
   "source": [
    "def_vectors_ind_footsep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:12:11.166307Z",
     "start_time": "2020-10-22T15:12:11.155337Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "feat_scaled=scaler.fit_transform(def_vectors_ind_footsep[def_vectors_ind_footsep.columns.difference(['player_name','team','position','off_val_opp_avg','foot_left'])].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:12:11.670861Z",
     "start_time": "2020-10-22T15:12:11.656866Z"
    }
   },
   "outputs": [],
   "source": [
    "def_vectors_footsep_scaled = pd.concat([def_vectors_ind_footsep[['player_name','team','position','off_val_opp_avg']],pd.DataFrame(feat_scaled,columns=def_vectors_ind_footsep.columns.difference(['player_name','team','position','off_val_opp_avg','foot_left']))],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:12:12.248227Z",
     "start_time": "2020-10-22T15:12:12.212354Z"
    }
   },
   "outputs": [],
   "source": [
    "def_vectors_footsep_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCB Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:23:58.937592Z",
     "start_time": "2020-10-22T19:23:58.920634Z"
    }
   },
   "outputs": [],
   "source": [
    "lcb_def_vectors = def_vectors_footsep_scaled[def_vectors_footsep_scaled['position']=='L_CB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:23:59.365128Z",
     "start_time": "2020-10-22T19:23:59.336208Z"
    }
   },
   "outputs": [],
   "source": [
    "lcb_def_vectors[lcb_def_vectors['player_name'].str.contains(\"Lap\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:23:59.760756Z",
     "start_time": "2020-10-22T19:23:59.748564Z"
    }
   },
   "outputs": [],
   "source": [
    "lcb_def_vectors.reset_index(inplace=True)\n",
    "lcb_def_vectors.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:24:00.380783Z",
     "start_time": "2020-10-22T19:24:00.349674Z"
    }
   },
   "outputs": [],
   "source": [
    "lcb_def_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:24:00.848311Z",
     "start_time": "2020-10-22T19:24:00.830697Z"
    }
   },
   "outputs": [],
   "source": [
    "lcb_def_vectors = lcb_def_vectors.merge(def_vectors[['player_name','team','position','footedness']],on=['player_name','position','team'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:24:02.560910Z",
     "start_time": "2020-10-22T19:24:01.288177Z"
    }
   },
   "outputs": [],
   "source": [
    "standard_embedding = umap.UMAP(random_state=np.random.RandomState(42)).fit_transform(lcb_def_vectors[lcb_def_vectors.columns.difference(['player_name','team','position','off_val_opp_avg','footedness'])].values)\n",
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:24:03.557108Z",
     "start_time": "2020-10-22T19:24:02.562870Z"
    }
   },
   "outputs": [],
   "source": [
    "clusterable_embedding = umap.UMAP(\n",
    "    n_neighbors=4,\n",
    "    min_dist=0.0,\n",
    "    n_components=2,\n",
    "    random_state=np.random.RandomState(42),\n",
    ").fit_transform(lcb_def_vectors[lcb_def_vectors.columns.difference(['player_name','team','position','off_val_opp_avg','footedness'])].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:24:03.566874Z",
     "start_time": "2020-10-22T19:24:03.558863Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = hdbscan.HDBSCAN(\n",
    "    min_samples=2,\n",
    "    min_cluster_size=5,\n",
    ").fit_predict(clusterable_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:25:38.546856Z",
     "start_time": "2020-10-22T19:25:38.171541Z"
    }
   },
   "outputs": [],
   "source": [
    "clustered = (labels >= 0)\n",
    "a0 = (labels==0)\n",
    "a1 = (labels==1)\n",
    "a2 = (labels==2)\n",
    "a3 = (labels==3)\n",
    "\n",
    "fig1 = plt.scatter(standard_embedding[~clustered, 0],\n",
    "            standard_embedding[~clustered, 1],\n",
    "            c=(0.5, 0.5, 0.5),\n",
    "            alpha=0.5)\n",
    "fig2 = plt.scatter(standard_embedding[a0, 0],\n",
    "            standard_embedding[a0, 1],\n",
    "            #c=labels[a0],\n",
    "            cmap='Spectral')\n",
    "fig3 = plt.scatter(standard_embedding[a1, 0],\n",
    "            standard_embedding[a1, 1],\n",
    "            #c=labels[a1],\n",
    "            cmap='Spectral')\n",
    "fig4 = plt.scatter(standard_embedding[a2, 0],\n",
    "            standard_embedding[a2, 1],\n",
    "            #c=labels[a2],\n",
    "            cmap='Spectral')\n",
    "fig5 = plt.scatter(standard_embedding[a3, 0],\n",
    "            standard_embedding[a3, 1],\n",
    "            #c=labels[a2],\n",
    "            cmap='Spectral')\n",
    "plt.legend([fig2, fig3, fig4, fig5], np.unique(labels))\n",
    "plt.title('LCB',fontsize=12,fontweight='bold')\n",
    "plt.figtext(0.5,0.01,'Silhouette Score = 0.809',ha='center',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg = silhouette_score(clusterable_embedding, labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcb_def_vectors['groups'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcb_def_vectors[lcb_def_vectors['groups']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.tree import _tree, DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "def pretty_print(df):\n",
    "    return display( HTML( df.to_html().replace(\"\\\\n\",\"<br>\") ) )\n",
    "\n",
    "def get_class_rules(tree: DecisionTreeClassifier, feature_names: list):\n",
    "  inner_tree: _tree.Tree = tree.tree_\n",
    "  classes = tree.classes_\n",
    "  class_rules_dict = dict()\n",
    "\n",
    "  def tree_dfs(node_id=0, current_rule=[]):\n",
    "    # feature[i] holds the feature to split on, for the internal node i.\n",
    "    split_feature = inner_tree.feature[node_id]\n",
    "    if split_feature != _tree.TREE_UNDEFINED: # internal node\n",
    "      name = feature_names[split_feature]\n",
    "      threshold = inner_tree.threshold[node_id]\n",
    "      # left child\n",
    "      left_rule = current_rule + [\"({} <= {})\".format(name, threshold)]\n",
    "      tree_dfs(inner_tree.children_left[node_id], left_rule)\n",
    "      # right child\n",
    "      right_rule = current_rule + [\"({} > {})\".format(name, threshold)]\n",
    "      tree_dfs(inner_tree.children_right[node_id], right_rule)\n",
    "    else: # leaf\n",
    "      dist = inner_tree.value[node_id][0]\n",
    "      dist = dist/dist.sum()\n",
    "      max_idx = dist.argmax()\n",
    "      if len(current_rule) == 0:\n",
    "        rule_string = \"ALL\"\n",
    "      else:\n",
    "        rule_string = \" and \".join(current_rule)\n",
    "      # register new rule to dictionary\n",
    "      selected_class = classes[max_idx]\n",
    "      class_probability = dist[max_idx]\n",
    "      class_rules = class_rules_dict.get(selected_class, [])\n",
    "      class_rules.append((rule_string, class_probability))\n",
    "      class_rules_dict[selected_class] = class_rules\n",
    "    \n",
    "  tree_dfs() # start from root, node_id = 0\n",
    "  return class_rules_dict\n",
    "\n",
    "def cluster_report(data: pd.DataFrame, clusters, min_samples_leaf=50, pruning_level=0.01):\n",
    "    # Create Model\n",
    "    tree = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf, ccp_alpha=pruning_level)\n",
    "    tree.fit(data, clusters)\n",
    "    \n",
    "    # Generate Report\n",
    "    feature_names = data.columns\n",
    "    class_rule_dict = get_class_rules(tree, feature_names)\n",
    "\n",
    "    report_class_list = []\n",
    "    for class_name in class_rule_dict.keys():\n",
    "        rule_list = class_rule_dict[class_name]\n",
    "        combined_string = \"\"\n",
    "        for rule in rule_list:\n",
    "            combined_string += \"[{}] {}\\n\\n\".format(rule[1], rule[0])\n",
    "        report_class_list.append((class_name, combined_string))\n",
    "        \n",
    "    cluster_instance_df = pd.Series(clusters).value_counts().reset_index()\n",
    "    cluster_instance_df.columns = ['class_name', 'instance_count']\n",
    "    report_df = pd.DataFrame(report_class_list, columns=['class_name', 'rule_list'])\n",
    "    report_df = pd.merge(cluster_instance_df, report_df, on='class_name', how='left')\n",
    "    pretty_print(report_df.sort_values(by='class_name')[['class_name', 'instance_count', 'rule_list']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_report(pd.DataFrame(clusterable_embedding,columns=['c0','c1']),labels,min_samples_leaf=2,pruning_level=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R_CB Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T17:50:12.737758Z",
     "start_time": "2020-10-22T17:50:12.728783Z"
    }
   },
   "outputs": [],
   "source": [
    "rcb_def_vectors = def_vectors_footsep_scaled[def_vectors_footsep_scaled['position']=='R_CB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T17:50:13.227124Z",
     "start_time": "2020-10-22T17:50:13.208183Z"
    }
   },
   "outputs": [],
   "source": [
    "rcb_def_vectors.reset_index(inplace=True)\n",
    "rcb_def_vectors.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T17:50:13.970449Z",
     "start_time": "2020-10-22T17:50:13.937487Z"
    }
   },
   "outputs": [],
   "source": [
    "rcb_def_vectors = rcb_def_vectors.merge(def_vectors[['player_name','team','position','footedness']],on=['player_name','position','team'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T17:50:15.668759Z",
     "start_time": "2020-10-22T17:50:14.488643Z"
    }
   },
   "outputs": [],
   "source": [
    "standard_embedding = umap.UMAP(random_state=np.random.RandomState(30)).fit_transform(rcb_def_vectors[rcb_def_vectors.columns.difference(['player_name','team','position','off_val_opp_avg','footedness'])].values)\n",
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1],s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T17:50:17.576946Z",
     "start_time": "2020-10-22T17:50:16.242717Z"
    }
   },
   "outputs": [],
   "source": [
    "clusterable_embedding = umap.UMAP(\n",
    "    n_neighbors=4,\n",
    "    min_dist=0.0,\n",
    "    n_components=2,\n",
    "    random_state=np.random.RandomState(30),\n",
    ").fit_transform(rcb_def_vectors[rcb_def_vectors.columns.difference(['player_name','team','position','off_val_opp_avg','footedness'])].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T17:50:18.282420Z",
     "start_time": "2020-10-22T17:50:18.262465Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = hdbscan.HDBSCAN(\n",
    "    min_samples=2,\n",
    "    min_cluster_size=5,\n",
    ").fit_predict(clusterable_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:17:18.738073Z",
     "start_time": "2020-10-22T19:17:18.275416Z"
    }
   },
   "outputs": [],
   "source": [
    "clustered = (labels >= 0)\n",
    "a0 = (labels==0)\n",
    "a1 = (labels==1)\n",
    "a2 = (labels==2)\n",
    "\n",
    "fig1 = plt.scatter(standard_embedding[~clustered, 0],\n",
    "            standard_embedding[~clustered, 1],\n",
    "            c=(0.5, 0.5, 0.5),\n",
    "            alpha=0.5)\n",
    "fig2 = plt.scatter(standard_embedding[a0, 0],\n",
    "            standard_embedding[a0, 1],\n",
    "            #c=labels[a0],\n",
    "            cmap='Spectral')\n",
    "fig3 = plt.scatter(standard_embedding[a1, 0],\n",
    "            standard_embedding[a1, 1],\n",
    "            #c=labels[a1],\n",
    "            cmap='Spectral')\n",
    "fig4 = plt.scatter(standard_embedding[a2, 0],\n",
    "            standard_embedding[a2, 1],\n",
    "            #c=labels[a2],\n",
    "            cmap='Spectral')\n",
    "plt.legend([fig2, fig3, fig4], np.unique(labels))\n",
    "plt.title('RCB',fontsize=12,fontweight='bold')\n",
    "plt.figtext(0.5,0.01,'Silhouette Score = 0.619',ha='center',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg = silhouette_score(clusterable_embedding, labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcb_def_vectors['groups'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcb_def_vectors[rcb_def_vectors['groups']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.tree import _tree, DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "def pretty_print(df):\n",
    "    return display( HTML( df.to_html().replace(\"\\\\n\",\"<br>\") ) )\n",
    "\n",
    "def get_class_rules(tree: DecisionTreeClassifier, feature_names: list):\n",
    "  inner_tree: _tree.Tree = tree.tree_\n",
    "  classes = tree.classes_\n",
    "  class_rules_dict = dict()\n",
    "\n",
    "  def tree_dfs(node_id=0, current_rule=[]):\n",
    "    # feature[i] holds the feature to split on, for the internal node i.\n",
    "    split_feature = inner_tree.feature[node_id]\n",
    "    if split_feature != _tree.TREE_UNDEFINED: # internal node\n",
    "      name = feature_names[split_feature]\n",
    "      threshold = inner_tree.threshold[node_id]\n",
    "      # left child\n",
    "      left_rule = current_rule + [\"({} <= {})\".format(name, threshold)]\n",
    "      tree_dfs(inner_tree.children_left[node_id], left_rule)\n",
    "      # right child\n",
    "      right_rule = current_rule + [\"({} > {})\".format(name, threshold)]\n",
    "      tree_dfs(inner_tree.children_right[node_id], right_rule)\n",
    "    else: # leaf\n",
    "      dist = inner_tree.value[node_id][0]\n",
    "      dist = dist/dist.sum()\n",
    "      max_idx = dist.argmax()\n",
    "      if len(current_rule) == 0:\n",
    "        rule_string = \"ALL\"\n",
    "      else:\n",
    "        rule_string = \" and \".join(current_rule)\n",
    "      # register new rule to dictionary\n",
    "      selected_class = classes[max_idx]\n",
    "      class_probability = dist[max_idx]\n",
    "      class_rules = class_rules_dict.get(selected_class, [])\n",
    "      class_rules.append((rule_string, class_probability))\n",
    "      class_rules_dict[selected_class] = class_rules\n",
    "    \n",
    "  tree_dfs() # start from root, node_id = 0\n",
    "  return class_rules_dict\n",
    "\n",
    "def cluster_report(data: pd.DataFrame, clusters, min_samples_leaf=50, pruning_level=0.01):\n",
    "    # Create Model\n",
    "    tree = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf, ccp_alpha=pruning_level)\n",
    "    tree.fit(data, clusters)\n",
    "    \n",
    "    # Generate Report\n",
    "    feature_names = data.columns\n",
    "    class_rule_dict = get_class_rules(tree, feature_names)\n",
    "\n",
    "    report_class_list = []\n",
    "    for class_name in class_rule_dict.keys():\n",
    "        rule_list = class_rule_dict[class_name]\n",
    "        combined_string = \"\"\n",
    "        for rule in rule_list:\n",
    "            combined_string += \"[{}] {}\\n\\n\".format(rule[1], rule[0])\n",
    "        report_class_list.append((class_name, combined_string))\n",
    "        \n",
    "    cluster_instance_df = pd.Series(clusters).value_counts().reset_index()\n",
    "    cluster_instance_df.columns = ['class_name', 'instance_count']\n",
    "    report_df = pd.DataFrame(report_class_list, columns=['class_name', 'rule_list'])\n",
    "    report_df = pd.merge(cluster_instance_df, report_df, on='class_name', how='left')\n",
    "    pretty_print(report_df.sort_values(by='class_name')[['class_name', 'instance_count', 'rule_list']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_report(pd.DataFrame(clusterable_embedding,columns=['c0','c1']),labels,min_samples_leaf=2,pruning_level=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:26:24.698375Z",
     "start_time": "2020-10-22T19:26:24.686499Z"
    }
   },
   "outputs": [],
   "source": [
    "lb_def_vectors = def_vectors_footsep_scaled[def_vectors_footsep_scaled['position']=='LB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:26:25.150838Z",
     "start_time": "2020-10-22T19:26:25.134574Z"
    }
   },
   "outputs": [],
   "source": [
    "lb_def_vectors.reset_index(inplace=True)\n",
    "lb_def_vectors.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:26:25.506078Z",
     "start_time": "2020-10-22T19:26:25.468197Z"
    }
   },
   "outputs": [],
   "source": [
    "lb_def_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:26:25.885703Z",
     "start_time": "2020-10-22T19:26:25.868737Z"
    }
   },
   "outputs": [],
   "source": [
    "lb_def_vectors = lb_def_vectors.merge(def_vectors[['player_name','team','position','footedness']],on=['player_name','position','team'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:26:27.569382Z",
     "start_time": "2020-10-22T19:26:26.331435Z"
    }
   },
   "outputs": [],
   "source": [
    "standard_embedding = umap.UMAP(random_state=np.random.RandomState(22)).fit_transform(lb_def_vectors[lb_def_vectors.columns.difference(['player_name','team','position','off_val_opp_avg','footedness'])].values)\n",
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1],s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:26:29.107140Z",
     "start_time": "2020-10-22T19:26:28.125330Z"
    }
   },
   "outputs": [],
   "source": [
    "clusterable_embedding = umap.UMAP(\n",
    "    n_neighbors=6,\n",
    "    min_dist=0.0,\n",
    "    n_components=2,\n",
    "    random_state=np.random.RandomState(22),\n",
    ").fit_transform(lb_def_vectors[lb_def_vectors.columns.difference(['player_name','team','position','off_val_opp_avg','footedness'])].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:26:31.301386Z",
     "start_time": "2020-10-22T19:26:31.277293Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = hdbscan.HDBSCAN(\n",
    "    min_samples=2,\n",
    "    min_cluster_size=6,\n",
    ").fit_predict(clusterable_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:26:38.487475Z",
     "start_time": "2020-10-22T19:26:38.469469Z"
    }
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:27:24.614054Z",
     "start_time": "2020-10-22T19:27:24.298045Z"
    }
   },
   "outputs": [],
   "source": [
    "clustered = (labels >= 0)\n",
    "a0 = (labels==0)\n",
    "a1 = (labels==1)\n",
    "a2 = (labels==2)\n",
    "fig1 = plt.scatter(standard_embedding[~clustered, 0],\n",
    "            standard_embedding[~clustered, 1],\n",
    "            c=(0.5, 0.5, 0.5),\n",
    "            alpha=0.5)\n",
    "fig2 = plt.scatter(standard_embedding[a0, 0],\n",
    "            standard_embedding[a0, 1],\n",
    "            #c=labels[a0],\n",
    "            cmap='Spectral')\n",
    "fig3 = plt.scatter(standard_embedding[a1, 0],\n",
    "            standard_embedding[a1, 1],\n",
    "            #c=labels[a1],\n",
    "            cmap='Spectral')\n",
    "fig4 = plt.scatter(standard_embedding[a2, 0],\n",
    "            standard_embedding[a2, 1],\n",
    "            #c=labels[a1],\n",
    "            cmap='Spectral')\n",
    "plt.legend([fig2, fig3, fig4], np.unique(labels))\n",
    "plt.title('LB',fontsize=12,fontweight='bold')\n",
    "plt.figtext(0.5,0.01,'Silhouette Score = 0.478',ha='center',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg = silhouette_score(clusterable_embedding, labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_def_vectors['groups'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_def_vectors[lb_def_vectors['groups']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from sklearn.tree import _tree, DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "def pretty_print(df):\n",
    "    return display( HTML( df.to_html().replace(\"\\\\n\",\"<br>\") ) )\n",
    "\n",
    "def get_class_rules(tree: DecisionTreeClassifier, feature_names: list):\n",
    "  inner_tree: _tree.Tree = tree.tree_\n",
    "  classes = tree.classes_\n",
    "  class_rules_dict = dict()\n",
    "\n",
    "  def tree_dfs(node_id=0, current_rule=[]):\n",
    "    # feature[i] holds the feature to split on, for the internal node i.\n",
    "    split_feature = inner_tree.feature[node_id]\n",
    "    if split_feature != _tree.TREE_UNDEFINED: # internal node\n",
    "      name = feature_names[split_feature]\n",
    "      threshold = inner_tree.threshold[node_id]\n",
    "      # left child\n",
    "      left_rule = current_rule + [\"({} <= {})\".format(name, threshold)]\n",
    "      tree_dfs(inner_tree.children_left[node_id], left_rule)\n",
    "      # right child\n",
    "      right_rule = current_rule + [\"({} > {})\".format(name, threshold)]\n",
    "      tree_dfs(inner_tree.children_right[node_id], right_rule)\n",
    "    else: # leaf\n",
    "      dist = inner_tree.value[node_id][0]\n",
    "      dist = dist/dist.sum()\n",
    "      max_idx = dist.argmax()\n",
    "      if len(current_rule) == 0:\n",
    "        rule_string = \"ALL\"\n",
    "      else:\n",
    "        rule_string = \" and \".join(current_rule)\n",
    "      # register new rule to dictionary\n",
    "      selected_class = classes[max_idx]\n",
    "      class_probability = dist[max_idx]\n",
    "      class_rules = class_rules_dict.get(selected_class, [])\n",
    "      class_rules.append((rule_string, class_probability))\n",
    "      class_rules_dict[selected_class] = class_rules\n",
    "    \n",
    "  tree_dfs() # start from root, node_id = 0\n",
    "  return class_rules_dict\n",
    "\n",
    "def cluster_report(data: pd.DataFrame, clusters, min_samples_leaf=50, pruning_level=0.01):\n",
    "    # Create Model\n",
    "    tree = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf, ccp_alpha=pruning_level)\n",
    "    tree.fit(data, clusters)\n",
    "    \n",
    "    # Generate Report\n",
    "    feature_names = data.columns\n",
    "    class_rule_dict = get_class_rules(tree, feature_names)\n",
    "\n",
    "    report_class_list = []\n",
    "    for class_name in class_rule_dict.keys():\n",
    "        rule_list = class_rule_dict[class_name]\n",
    "        combined_string = \"\"\n",
    "        for rule in rule_list:\n",
    "            combined_string += \"[{}] {}\\n\\n\".format(rule[1], rule[0])\n",
    "        report_class_list.append((class_name, combined_string))\n",
    "        \n",
    "    cluster_instance_df = pd.Series(clusters).value_counts().reset_index()\n",
    "    cluster_instance_df.columns = ['class_name', 'instance_count']\n",
    "    report_df = pd.DataFrame(report_class_list, columns=['class_name', 'rule_list'])\n",
    "    report_df = pd.merge(cluster_instance_df, report_df, on='class_name', how='left')\n",
    "    pretty_print(report_df.sort_values(by='class_name')[['class_name', 'instance_count', 'rule_list']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_report(pd.DataFrame(clusterable_embedding,columns=['c0','c1']),labels,min_samples_leaf=2,pruning_level=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RB Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:27:31.734138Z",
     "start_time": "2020-10-22T19:27:31.728167Z"
    }
   },
   "outputs": [],
   "source": [
    "rb_def_vectors = def_vectors_footsep_scaled[def_vectors_footsep_scaled['position']=='RB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:27:32.396906Z",
     "start_time": "2020-10-22T19:27:32.378931Z"
    }
   },
   "outputs": [],
   "source": [
    "rb_def_vectors.reset_index(inplace=True)\n",
    "rb_def_vectors.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:27:32.949548Z",
     "start_time": "2020-10-22T19:27:32.893192Z"
    }
   },
   "outputs": [],
   "source": [
    "rb_def_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:27:33.467215Z",
     "start_time": "2020-10-22T19:27:33.452270Z"
    }
   },
   "outputs": [],
   "source": [
    "rb_def_vectors = rb_def_vectors.merge(def_vectors[['player_name','team','position','footedness']],on=['player_name','position','team'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:27:37.025925Z",
     "start_time": "2020-10-22T19:27:34.494514Z"
    }
   },
   "outputs": [],
   "source": [
    "standard_embedding = umap.UMAP(random_state=np.random.RandomState(22),learning_rate=1).fit_transform(rb_def_vectors[rb_def_vectors.columns.difference(['player_name','team','position','off_val_opp_avg','footedness'])].values)\n",
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1],s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:27:38.819350Z",
     "start_time": "2020-10-22T19:27:37.842949Z"
    }
   },
   "outputs": [],
   "source": [
    "clusterable_embedding = umap.UMAP(\n",
    "    n_neighbors=6,\n",
    "    min_dist=0.0,\n",
    "    n_components=2,\n",
    "    random_state=np.random.RandomState(22),\n",
    ").fit_transform(rb_def_vectors[rb_def_vectors.columns.difference(['player_name','team','position','off_val_opp_avg','footedness'])].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:27:38.829283Z",
     "start_time": "2020-10-22T19:27:38.821295Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = hdbscan.HDBSCAN(\n",
    "    min_samples=2,\n",
    "    min_cluster_size=6,\n",
    ").fit_predict(clusterable_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:27:45.343592Z",
     "start_time": "2020-10-22T19:27:45.329627Z"
    }
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T19:27:58.052157Z",
     "start_time": "2020-10-22T19:27:57.685009Z"
    }
   },
   "outputs": [],
   "source": [
    "clustered = (labels >= 0)\n",
    "a0 = (labels==0)\n",
    "a1 = (labels==1)\n",
    "a2 = (labels==2)\n",
    "\n",
    "fig1 = plt.scatter(standard_embedding[~clustered, 0],\n",
    "            standard_embedding[~clustered, 1],\n",
    "            c=(0.5, 0.5, 0.5),\n",
    "            alpha=0.5)\n",
    "fig2 = plt.scatter(standard_embedding[a0, 0],\n",
    "            standard_embedding[a0, 1],\n",
    "            #c=labels[a0],\n",
    "            cmap='Spectral')\n",
    "fig3 = plt.scatter(standard_embedding[a1, 0],\n",
    "            standard_embedding[a1, 1],\n",
    "            #c=labels[a1],\n",
    "            cmap='Spectral')\n",
    "fig4 = plt.scatter(standard_embedding[a2, 0],\n",
    "            standard_embedding[a2, 1],\n",
    "            #c=labels[a2],\n",
    "            cmap='Spectral')\n",
    "plt.legend([fig1, fig2, fig3, fig4], np.unique(labels))\n",
    "plt.title('RB',fontsize=12,fontweight='bold')\n",
    "plt.figtext(0.5,0.01,'Silhouette Score = 0.424',ha='center',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg = silhouette_score(clusterable_embedding, labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_def_vectors['groups'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_def_vectors[rb_def_vectors['groups']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from sklearn.tree import _tree, DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "def pretty_print(df):\n",
    "    return display( HTML( df.to_html().replace(\"\\\\n\",\"<br>\") ) )\n",
    "\n",
    "def get_class_rules(tree: DecisionTreeClassifier, feature_names: list):\n",
    "  inner_tree: _tree.Tree = tree.tree_\n",
    "  classes = tree.classes_\n",
    "  class_rules_dict = dict()\n",
    "\n",
    "  def tree_dfs(node_id=0, current_rule=[]):\n",
    "    # feature[i] holds the feature to split on, for the internal node i.\n",
    "    split_feature = inner_tree.feature[node_id]\n",
    "    if split_feature != _tree.TREE_UNDEFINED: # internal node\n",
    "      name = feature_names[split_feature]\n",
    "      threshold = inner_tree.threshold[node_id]\n",
    "      # left child\n",
    "      left_rule = current_rule + [\"({} <= {})\".format(name, threshold)]\n",
    "      tree_dfs(inner_tree.children_left[node_id], left_rule)\n",
    "      # right child\n",
    "      right_rule = current_rule + [\"({} > {})\".format(name, threshold)]\n",
    "      tree_dfs(inner_tree.children_right[node_id], right_rule)\n",
    "    else: # leaf\n",
    "      dist = inner_tree.value[node_id][0]\n",
    "      dist = dist/dist.sum()\n",
    "      max_idx = dist.argmax()\n",
    "      if len(current_rule) == 0:\n",
    "        rule_string = \"ALL\"\n",
    "      else:\n",
    "        rule_string = \" and \".join(current_rule)\n",
    "      # register new rule to dictionary\n",
    "      selected_class = classes[max_idx]\n",
    "      class_probability = dist[max_idx]\n",
    "      class_rules = class_rules_dict.get(selected_class, [])\n",
    "      class_rules.append((rule_string, class_probability))\n",
    "      class_rules_dict[selected_class] = class_rules\n",
    "    \n",
    "  tree_dfs() # start from root, node_id = 0\n",
    "  return class_rules_dict\n",
    "\n",
    "def cluster_report(data: pd.DataFrame, clusters, min_samples_leaf=50, pruning_level=0.01):\n",
    "    # Create Model\n",
    "    tree = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf, ccp_alpha=pruning_level)\n",
    "    tree.fit(data, clusters)\n",
    "    \n",
    "    # Generate Report\n",
    "    feature_names = data.columns\n",
    "    class_rule_dict = get_class_rules(tree, feature_names)\n",
    "\n",
    "    report_class_list = []\n",
    "    for class_name in class_rule_dict.keys():\n",
    "        rule_list = class_rule_dict[class_name]\n",
    "        combined_string = \"\"\n",
    "        for rule in rule_list:\n",
    "            combined_string += \"[{}] {}\\n\\n\".format(rule[1], rule[0])\n",
    "        report_class_list.append((class_name, combined_string))\n",
    "        \n",
    "    cluster_instance_df = pd.Series(clusters).value_counts().reset_index()\n",
    "    cluster_instance_df.columns = ['class_name', 'instance_count']\n",
    "    report_df = pd.DataFrame(report_class_list, columns=['class_name', 'rule_list'])\n",
    "    report_df = pd.merge(cluster_instance_df, report_df, on='class_name', how='left')\n",
    "    pretty_print(report_df.sort_values(by='class_name')[['class_name', 'instance_count', 'rule_list']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_report(pd.DataFrame(clusterable_embedding,columns=['c0','c1']),labels,min_samples_leaf=4,pruning_level=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the groups to lineups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_clusters = ['rlll', 'rrll', 'rrlr', 'rrrl', 'rrrr']\n",
    "df_fourclusters = pd.concat(\n",
    "    (pd.read_pickle(f'../data/clusters/clusters_vaep/cluster_{i}.pkl')\n",
    "     for i in four_clusters),\n",
    "    axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team=pd.DataFrame(df_fourclusters.groupby(['team','RB','R_CB','L_CB','LB'])['wyId'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team[df_4clusters_team['team'].str.contains(\"Chelsea\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " player_map = {  'RamiroFunesMori': 'JoseRamiroFunesMori',\n",
    "                'KurtZouma': 'KurtHappyZouma',\n",
    "                'Danilo': 'DaniloLuizdaSilva',\n",
    "                'CesarAzpilicueta': 'CesarAzpilicuetaTanco',\n",
    "                'EzequielSchelotto': 'MatiasEzequielSchelotto',\n",
    "                'GaetanBong': 'GaetanBongSongo',\n",
    "                'HectorBellerin': 'HectorBellerinMoruno',\n",
    "                'AhmedHegazi': 'AhmedHegazy',\n",
    "                'JamaalLascelles': 'JamalLascelles',\n",
    "                'AngelRangel': 'AngelRangelZaragoza',\n",
    "                'Zanka': 'MathiasJattahNjieJorgensen',\n",
    "                'EricBailly': 'EricBertrandBailly',\n",
    "                'MarcosRojo': 'FaustinoMarcosAlbertoRojo',\n",
    "                'AngeloOgbonna': 'AngeloObinzeOgbonna',\n",
    "                'DavinsonSanchez': 'DavinsonSanchezMina',\n",
    "                'JavierManquillo': 'JavierManquilloGaitan',\n",
    "                'TommySmith': 'TomSmith',\n",
    "                'Bruno': 'BrunoSaltorGrau',\n",
    "                'JosephGomez': 'JoeGomez',\n",
    "                'AlbertoMoreno':'AlbertoMorenoPerez',\n",
    "                'LuisAntonioValencia':'LuisAntonioValenciaMosquera',\n",
    "                'NicolasOtamendi':'NicolasHernanOtamendi',\n",
    "                'NachoMonreal':'IgnacioMonrealEraso',\n",
    "                'CedricSoares':'CedricRicardoAlvesSoares',\n",
    "                'JoelMatip':'JoelAndreJobMatip',\n",
    "                'MiguelBritos':'MiguelAngelBritosCabrera',\n",
    "                'VictorLindelof':'VictorNilssonLindelof',\n",
    "                'JamesCollins':'JamesMichaelCollins',\n",
    "                'CucoMartina':'RhuendlyMartina',\n",
    "                'DavidLuiz':'DavidLuizMoreiraMarinho',\n",
    "                'ChancelMbemba':'ChancelMbembaMangulu',\n",
    "                'PabloZabaleta':'PabloJavierZabaletaGirod',\n",
    "                'KikoFemenia':'FranciscoFemeniaFar',\n",
    "                'JoseFonte':'JoseMigueldaRochaFonte',\n",
    "                'JesusGamez':'JesusGamezDuarte'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = ['RB','R_CB','L_CB','LB']\n",
    "for index,row in df_4clusters_team.iterrows():\n",
    "    for pos in positions:\n",
    "        try:\n",
    "            replace = player_map[row[pos]]\n",
    "        except:\n",
    "            continue\n",
    "        df_4clusters_team[pos][index] = replace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team[df_4clusters_team['team'].str.contains(\"Manchester City\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team.rename(columns = {'wyId':'matches_played'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team = df_4clusters_team.merge(rb_def_vectors[['player_name','team','groups']], how = 'left',\n",
    "                                            left_on=['RB','team'], right_on = ['player_name','team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team.drop(['player_name'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team.rename(columns = {'groups':'RB_groups'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team = df_4clusters_team.merge(rcb_def_vectors[['player_name','team','groups']], how = 'left',\n",
    "                                            left_on=['R_CB','team'], right_on = ['player_name','team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team.drop(['player_name'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team.rename(columns = {'groups':'R_CB_groups'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team = df_4clusters_team.merge(lcb_def_vectors[['player_name','team','groups']], how = 'left',\n",
    "                                            left_on=['L_CB','team'], right_on = ['player_name','team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team.drop(['player_name'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team.rename(columns = {'groups':'L_CB_groups'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team[df_4clusters_team['team'].str.contains(\"Tottenham Hotspur\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team = df_4clusters_team.merge(lb_def_vectors[['player_name','team','groups']], how ='left',\n",
    "                                            left_on=['LB','team'], right_on = ['player_name','team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team.drop(['player_name'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team.rename(columns = {'groups':'LB_groups'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team[df_4clusters_team['team'].str.contains(\"West Bromwich Albion\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_five = ['Manchester City','Manchester United','Tottenham Hotspur','Liverpool','Chelsea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_five = ['Huddersfield Town','Southampton','Swansea City','Stoke City','West Bromwich Albion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4clusters_team[df_4clusters_team['team'].str.contains(\"Manchester United\")].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= pd.DataFrame(df_4clusters_team[df_4clusters_team['team'].str.contains(\"Manchester United\")].groupby(['RB_groups','R_CB_groups','L_CB_groups','LB_groups'])['matches_played'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_vectors_ind_footsep_lcb = def_vectors_ind_footsep.merge(lcb_def_vectors[['player_name','position','team','groups']],on=['player_name','team','position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(def_vectors_ind_footsep_lcb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_vectors_ind_footsep_rcb = def_vectors_ind_footsep.merge(rcb_def_vectors[['player_name','position','team','groups']],on=['player_name','team','position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(def_vectors_ind_footsep_rcb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_vectors_ind_footsep_lb = def_vectors_ind_footsep.merge(lb_def_vectors[['player_name','position','team','groups']],on=['player_name','team','position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(def_vectors_ind_footsep_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_vectors_ind_footsep_rb = def_vectors_ind_footsep.merge(rb_def_vectors[['player_name','position','team','groups']],on=['player_name','team','position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(def_vectors_ind_footsep_rb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_vectors_ind_footsep_lb[def_vectors_ind_footsep_lb['groups']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_vectors_ind_footsep_lb[def_vectors_ind_footsep_lb['groups']==0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_vectors_ind_footsep_lb[def_vectors_ind_footsep_lb['groups']==1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_vectors_ind_footsep_lb[def_vectors_ind_footsep_lb['groups']==2].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_vectors_ind_footsep_lb[def_vectors_ind_footsep_lb['groups']==3].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region_graph(df,pref_cols,acc_cols,off_cols,offcontri_cols,pos):\n",
    "    groups = df['groups'].unique()\n",
    "    groups = np.sort(groups)\n",
    "    groups = [g for g in groups if g!=-1]\n",
    "    print(groups)\n",
    "    cols = ['pref','acc','off','contri']\n",
    "    groups_list_pref,groups_list_acc,groups_list_off,groups_list_offcontri = list(),list(),list(),list()\n",
    "    for g in groups:\n",
    "        groups_list_pref.append([np.round(df[df['groups']==g][c].median(),2) for c in pref_cols])\n",
    "        groups_list_acc.append([np.round(df[df['groups']==g][c].median(),2) for c in acc_cols])\n",
    "        groups_list_off.append([np.round(df[df['groups']==g][c].median(),2) for c in off_cols])\n",
    "        groups_list_offcontri.append([np.round(df[df['groups']==g][c].median(),2) for c in offcontri_cols])\n",
    "    \n",
    "    barWidth = 0.2\n",
    "    r_list_pref,r_list_acc,r_list_off,r_list_offcontri = [None]*len(groups_list_pref),[None]*len(groups_list_acc),[None]*len(groups_list_off),[None]*len(groups_list_offcontri)\n",
    "    r_list_pref[0] = np.arange(len(groups_list_pref[0]))\n",
    "    r_list_acc[0] = np.arange(len(groups_list_acc[0]))\n",
    "    r_list_off[0] = np.arange(len(groups_list_off[0]))\n",
    "    r_list_offcontri[0] = np.arange(len(groups_list_offcontri[0]))\n",
    "    for g in range(1,len(groups_list_pref)):\n",
    "        r_list_pref[g] = ([x + barWidth for x in r_list_pref[g-1]])\n",
    "    for g in range(1,len(groups_list_acc)):\n",
    "        r_list_acc[g] = ([x + barWidth for x in r_list_acc[g-1]])\n",
    "    for g in range(1,len(groups_list_off)):\n",
    "        r_list_off[g] = ([x + barWidth for x in r_list_off[g-1]])\n",
    "    for g in range(1,len(groups_list_offcontri)):\n",
    "        r_list_offcontri[g] = ([x + barWidth for x in r_list_offcontri[g-1]])\n",
    "    \n",
    "    # Make the plot\n",
    "    bars_pref,bars_acc,bars_off,bars_offcontri = list(),list(),list(),list()\n",
    "    fig, axes = plt.subplots(2, 2, figsize = (15,10)) \n",
    "    for r in range(len(r_list_pref)):\n",
    "        bars_pref.append(axes[0,0].bar(r_list_pref[r], groups_list_pref[r], width=barWidth, label=r))\n",
    "    for r in range(len(r_list_acc)):\n",
    "        bars_acc.append(axes[0,1].bar(r_list_acc[r], groups_list_acc[r], width=barWidth, label=r))\n",
    "    for r in range(len(r_list_off)):\n",
    "        bars_off.append(axes[1,0].bar(r_list_off[r], groups_list_off[r], width=barWidth, label=r))\n",
    "    for r in range(len(r_list_offcontri)):\n",
    "        bars_offcontri.append(axes[1,1].bar(r_list_offcontri[r], groups_list_offcontri[r], width=barWidth, label=r))\n",
    "    axes[0,0].set_xticks([r + barWidth for r in range(len(groups_list_pref[0]))])\n",
    "    axes[0,0].set_xticklabels(['LF','LC','RC','RF'])\n",
    "    axes[0,1].set_xticks([r + barWidth for r in range(len(groups_list_pref[0]))])\n",
    "    axes[0,1].set_xticklabels(['LF','LC','RC','RF'])\n",
    "    axes[1,0].set_xticks([r + barWidth for r in range(len(groups_list_pref[0]))])\n",
    "    axes[1,0].set_xticklabels(['LF','LC','RC','RF'])\n",
    "    axes[1,1].set_xticks([r + barWidth for r in range(len(groups_list_pref[0]))])\n",
    "    axes[1,1].set_xticklabels(['LF','LC','RC','RF'])\n",
    "#    axes[1,1].axhline(y=0.93,linewidth=1, color='k')\n",
    "#    axes[1,1].text(0,0.93,\"0 contri\", position=(-0.3,0.92), ha = 'right',fontsize=14)\n",
    "    axes[0,0].set_title('Progressive Pass Preference (in %)',fontweight='bold')\n",
    "    axes[0,1].set_title('Progressive Pass Accuracy (in %)',fontweight='bold')\n",
    "    axes[1,0].set_title('Offensive Value per Progressive Pass',fontweight='bold')\n",
    "    axes[1,1].set_title('Offensive Contribution',fontweight='bold')\n",
    "    axes[0,0].tick_params(axis='both', which='major', labelsize=14)\n",
    "    axes[0,1].tick_params(axis='both', which='major', labelsize=14)\n",
    "    axes[1,0].tick_params(axis='both', which='major', labelsize=14)\n",
    "    axes[1,1].tick_params(axis='both', which='major', labelsize=14)\n",
    "    \n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc=(0.65,0.94), ncol = len(groups))\n",
    "    fig.text(0.5, 0.07, 'Regions', ha='center',fontsize = 14,fontweight='bold')\n",
    "    fig.text(0.07, 0.5, 'Values', va='center', rotation='vertical', fontsize = 14,fontweight='bold')\n",
    "    plt.savefig(\"../paper_charts/\"+pos)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_region_graph(def_vectors_ind_footsep_lb,\n",
    "                 pref_cols = ['att_LF_pref','att_LC_pref','att_RC_pref','att_RF_pref'],\n",
    "                 acc_cols = ['att_LF_acc','att_LC_acc','att_RC_acc','att_RF_acc'],\n",
    "                 off_cols = ['att_LF_off','att_LC_off','att_RC_off','att_RF_off'],\n",
    "                 offcontri_cols = ['att_LF_offcontri','att_LC_offcontri','att_RC_offcontri','att_RF_offcontri'],\n",
    "                 pos = \"LB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
